
#include "atomic.h"

/*
*  This version preallocate all the necessary memory during initialization.
*  Its purpose is to eliminate the cost of dynamic memory allocation and
*  deallocation. Memory is never realeased and should never be allocated.
*  A profile file (given by the environment variable PROF_FILE) contains the
*  estimated size for each category (the information is acquired during a
*  profile phase generated by the .profile version).
*
*  Note: this will probably not work if threads are reassigned to a transaction
*  multiple times (e.g. Kmeans)
*/

/* Max number of threads allowed */
#define NUM_THREAD 32

/* This should equal the number of categories used in the profile */
#define NUM_CATEGORIES 128

/* structured used to store the preallocated memory */
typedef struct mem_cache {
  void **class[NUM_CATEGORIES+1];       /* the address pointers for each class */
  unsigned int size[NUM_CATEGORIES+1];  /* number of pointers contained in each class */
  unsigned int top[NUM_CATEGORIES+1];   /* pointer to the current address of each class */
} mem_cache_t;
/*****************************************************************************/



typedef struct mod_cb_info {
  unsigned short commit_size;           /* Array size for commit callbacks */
  unsigned short commit_nb;             /* Number of commit callbacks */
  mod_cb_entry_t *commit;               /* Commit callback entries */
  unsigned short abort_size;            /* Array size for abort callbacks */
  unsigned short abort_nb;              /* Number of abort callbacks */
  mod_cb_entry_t *abort;                /* Abort callback entries */


/*****************************************************************************/
  mem_cache_t *cache;                   /* preallocated memory for each class */
  unsigned long mallocs;                /* total number of mallocs */         
  unsigned long misses;                 /* mallocs that missed the cache */

/* transaction stats */
  unsigned long commits;
  unsigned long aborts;
/*****************************************************************************/

} mod_cb_info_t;


/*****************************************************************************/
/* each thread needs an ID - we use this global variable to assign the ID at
   thread init */
static int thread_id = 0;

/* the global vector holding the preallocated memory 
   the whole memory is allocated during the module start up and assigned to 
   each thread during thread initialization
 */
static mem_cache_t ALIGNED cache[NUM_THREAD];
/*****************************************************************************/



static INLINE void
mod_cb_add_on_abort(mod_cb_info_t *icb, void (*f)(void *arg), void *arg)
{
  if (unlikely(icb->abort_nb >= icb->abort_size)) {
    icb->abort_size *= 2;
    icb->abort = xrealloc(icb->abort, sizeof(mod_cb_entry_t) * icb->abort_size);
    if (icb->abort == NULL) {
      perror("realloc error");
      exit(1);
    }
  }
  icb->abort[icb->abort_nb].f = f;
  icb->abort[icb->abort_nb].arg = arg;
  icb->abort_nb++;
}


static INLINE void
mod_cb_add_on_commit(mod_cb_info_t *icb, void (*f)(void *arg), void *arg)
{
  if (unlikely(icb->commit_nb >= icb->commit_size)) {
    icb->commit_size *= 2;
    icb->commit = xrealloc(icb->commit, sizeof(mod_cb_entry_t) * icb->commit_size);
    if (icb->commit == NULL) {
      perror("realloc error");
      exit(1);
    }
  }
  icb->commit[icb->commit_nb].f = f;
  icb->commit[icb->commit_nb].arg = arg;
  icb->commit_nb++;
}



/* ################################################################### *
 * MEMORY ALLOCATION FUNCTIONS
 * ################################################################### */
static INLINE void *
int_stm_malloc(struct stm_tx *tx, size_t size)
{
  /* Memory will be freed upon abort */
  mod_cb_info_t *icb;
  void *addr;

  assert(mod_cb.key >= 0);
  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);

  /* Round up size */
  if (sizeof(stm_word_t) == 4) {
    size = (size + 3) & ~(size_t)0x03;
  } else {
    size = (size + 7) & ~(size_t)0x07;
  }



/*****************************************************************************/
  icb->mallocs++; /* counts the number of mallocs */

  int category = size >> 3;
  if (unlikely(category > NUM_CATEGORIES)) {
    perror("invalid category");
    exit(1);
  } 
  if (icb->cache->top[category] < icb->cache->size[category]) {
    return icb->cache->class[category][icb->cache->top[category]++];
  }

  /* if we get here, a miss ocurred */
  icb->misses++;
/*****************************************************************************/
 
 

  if (unlikely((addr = malloc(size)) == NULL)) {
    perror("malloc");
    exit(1);
  }

/*****************************************************************************/
/* no memory is ever freed
  mod_cb_add_on_abort(icb, free, addr);
*/
/*****************************************************************************/

  return addr;
}


static inline
void *int_stm_calloc(struct stm_tx *tx, size_t nm, size_t size)
{
  /* Memory will be freed upon abort */
  mod_cb_info_t *icb;
  void *addr;

  assert(mod_cb.key >= 0);
  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);

  /* Round up size */
  if (sizeof(stm_word_t) == 4) {
    size = (size + 3) & ~(size_t)0x03;
  } else {
    size = (size + 7) & ~(size_t)0x07;
  }


/*****************************************************************************/
  icb->mallocs++; /* counts the number of mallocs */

  int category = size >> 3;
  if (unlikely(category > NUM_CATEGORIES)) {
    perror("invalid category");
    exit(1);
  } 
  if (icb->cache->top[category] < icb->cache->size[category]) {
    return icb->cache->class[category][icb->cache->top[category]++];
  }

  /* if we get here, a miss ocurred */
  icb->misses++;
/*****************************************************************************/
  

  if ((addr = calloc(nm, size)) == NULL) {
    perror("calloc");
    exit(1);
  }

/*****************************************************************************/
/* no memory is ever freed
  mod_cb_add_on_abort(icb, free, addr);
*/
/*****************************************************************************/

  return addr;
}


#ifdef EPOCH_GC
static void
epoch_free(void *addr)
{
  if (mod_cb.use_gc) {
    /* TODO use tx->end could be also used */
    stm_word_t t = stm_get_clock();
    gc_free(addr, t);
  } else {
    free(addr);
  }
}
#endif /* EPOCH_GC */

static inline
void int_stm_free2(struct stm_tx *tx, void *addr, size_t idx, size_t size)
{
  /* Memory disposal is delayed until commit */
  mod_cb_info_t *icb;

  assert(mod_cb.key >= 0);
  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);

  /* TODO: if block allocated in same transaction => no need to overwrite */
  if (size > 0) {
    stm_word_t *a;
    /* Overwrite to prevent inconsistent reads */
    if (sizeof(stm_word_t) == 4) {
      idx = (idx + 3) >> 2;
      size = (size + 3) >> 2;
    } else {
      idx = (idx + 7) >> 3;
      size = (size + 7) >> 3;
    }
    a = (stm_word_t *)addr + idx;
    while (size-- > 0) {
      /* Acquire lock and update version number */
      stm_store2_tx(tx, a++, 0, 0);
    }
  }
  /* Schedule for removal */

#ifdef EPOCH_GC
  mod_cb_add_on_commit(icb, epoch_free, addr);
#else /* ! EPOCH_GC */

/*****************************************************************************/
/* disconsider free()s
  mod_cb_add_on_commit(icb, free, addr);
*/
/*****************************************************************************/

#endif /* ! EPOCH_GC */
}




/*
 * Called upon transaction commit.
 */
static void mod_cb_on_commit(void *arg)
{
  mod_cb_info_t *icb;

  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);

/*****************************************************************************/
  icb->commits++;
/*****************************************************************************/

  /* Call commit callback */
  while (icb->commit_nb > 0) {
    icb->commit_nb--;
    icb->commit[icb->commit_nb].f(icb->commit[icb->commit_nb].arg);
  }
  /* Reset abort callback */
  icb->abort_nb = 0;
}

/*
 * Called upon transaction abort.
 */
static void mod_cb_on_abort(void *arg)
{
  mod_cb_info_t *icb;

  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);

/*****************************************************************************/
  icb->aborts++;
/*****************************************************************************/

  /* Call abort callback */
  while (icb->abort_nb > 0) {
    icb->abort_nb--;
    icb->abort[icb->abort_nb].f(icb->abort[icb->abort_nb].arg);
  }
  /* Reset commit callback */
  icb->commit_nb = 0;
}

/*
 * Called upon thread creation.
 */
static void mod_cb_on_thread_init(void *arg)
{
  mod_cb_info_t *icb;

  if ((icb = (mod_cb_info_t *)xmalloc(sizeof(mod_cb_info_t))) == NULL)
    goto err_malloc;
  icb->commit_nb = icb->abort_nb = 0;
  icb->commit_size = icb->abort_size = DEFAULT_CB_SIZE;
  icb->commit = xmalloc(sizeof(mod_cb_entry_t) * icb->commit_size);
  icb->abort = xmalloc(sizeof(mod_cb_entry_t) * icb->abort_size);
  if (unlikely(icb->commit == NULL || icb->abort == NULL))
    goto err_malloc;



/*****************************************************************************/
/* assign a unique ID to each thread */
  int id;
retry_id:
  id = ATOMIC_LOAD(&thread_id);
  if (ATOMIC_CAS_FULL(&thread_id, id, id+1) == 0)
      goto retry_id;
  
  if (id >= NUM_THREAD) {
    perror("invalid id");
    exit(1);
  }

  icb->cache = &cache[id];

  icb->mallocs = 0;
  icb->misses = 0;

  icb->commits = 0;
  icb->aborts = 0;
/*****************************************************************************/



  stm_set_specific(mod_cb.key, icb);

  return;
 err_malloc:
   perror("malloc");
   exit(1);
}

/*
 * Called upon thread deletion.
 */
static void mod_cb_on_thread_exit(void *arg)
{
  mod_cb_info_t *icb;

  icb = (mod_cb_info_t *)stm_get_specific(mod_cb.key);
  assert(icb != NULL);



/*****************************************************************************/
  int i;
  unsigned long left = 0;
  for (i=1; i<NUM_CATEGORIES+1; i++) {
    left += (icb->cache->size[i] - icb->cache->top[i]);
  }

  fprintf(stdout, "\nmallocs = %lu misses = %lu left = %lu [c = %lu, a = %lu]\n", 
          icb->mallocs, icb->misses, left, icb->commits, icb->aborts);


/* deallocate preallocated memory */
/* skip deallocation (this still counts towards execution time)
  for (i=1; i<NUM_CATEGORIES+1; i++) {

    int j;
    for (j=0; j < icb->cache->size[i]; j++)
      free(icb->cache->class[i][j]);

    free(icb->cache->class[i]);

  }
*/
/*****************************************************************************/

  xfree(icb->abort);
  xfree(icb->commit);
  xfree(icb);
}


static INLINE void
mod_cb_mem_init(void)
{
  if (mod_cb.key >= 0)
    goto already_init;

  stm_register(mod_cb_on_thread_init, mod_cb_on_thread_exit, NULL, NULL, mod_cb_on_commit, mod_cb_on_abort, NULL);
  mod_cb.key = stm_create_specific();
  if (unlikely(mod_cb.key < 0)) {
    fprintf(stderr, "Cannot create specific key\n");
    exit(1);
  }

 already_init:
  return;
}


void mod_mem_init(int use_gc)
{
  mod_cb_mem_init();
#ifdef EPOCH_GC
  mod_cb.use_gc = use_gc;
#endif /* EPOCH_GC */


/*****************************************************************************/
/*
 * Read the file specified by the environment variable 'PROF_FILE' and allocate
 * all the required memory specified by that file.
 * This file must be in tandem with .profile.
 */
  char *s;
  s = getenv("PROF_FILE");
  if (s == NULL)
  {
    fprintf(stderr, "PROF_FILE environment variable is empty\n");
    exit(1);
  }
  FILE *fp;
  if ((fp = fopen(s, "r")) == NULL) {
    fprintf(stderr, "Profile file %s could not be opened\n", s); 
    exit(1);
  }

  /*
   The format of the input file is:
     <num_threads>
     <cat_id> <mallocs>
     ...
     <cat_id> <mallocs>

   There is a maximum of 128 different '<cat_id> <mallocs>'.
   No validation is performed for consistency.
  */

  char buf[100];
  fgets(buf, 100, fp);
  char *ch;
  long int num_thread = strtol(buf, &ch, 10);
  if (num_thread > NUM_THREAD) {
    perror("invalid thread number");
    exit(1);
  }

  /* read the following NUM_CATEGORIES lines, each containing a category and
     the number of mallocs */
  int i;
  for (i=1; i<NUM_CATEGORIES+1; i++) {
    long int classid, classqt;
    fgets(buf, 100, fp);
    classid = strtol(buf, &ch, 10); /* <cat_id>  */
    classqt = strtol(ch, NULL, 10); /* <mallocs> */
  
    /* allocate memory for each thread */
    int nt;
    for (nt=0; nt<num_thread; nt++) {
    
      cache[nt].size[classid] = classqt;
      cache[nt].top[classid] = 0;

      if (cache[nt].size[classid] != 0) {
        /* first allocate the list of pointers for each category */
        cache[nt].class[classid] = malloc(sizeof(void *) * classqt);
        if (unlikely(cache[nt].class[classid] == NULL)) {
          perror("malloc");
	  exit(1);
        }
        /* now preallocate the memory */
        int j;
        for (j=0; j < classqt; j++)
          cache[nt].class[classid][j] = malloc(classid*8);
      }
    }
  }

  fclose(fp);
/*****************************************************************************/

}
